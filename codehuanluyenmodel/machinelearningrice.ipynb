{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13407977,"sourceType":"datasetVersion","datasetId":8509267}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import datasets, transforms, models\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n\n# --- Ki·ªÉm tra GPU ---\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"ƒêang s·ª≠ d·ª•ng thi·∫øt b·ªã:\", device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-20T15:03:27.917040Z","iopub.execute_input":"2025-10-20T15:03:27.917539Z","iopub.status.idle":"2025-10-20T15:03:36.246062Z","shell.execute_reply.started":"2025-10-20T15:03:27.917515Z","shell.execute_reply":"2025-10-20T15:03:36.245430Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir = \"/kaggle/input/gaodataset2-2/gaodataset2\"\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\ndataset = datasets.ImageFolder(root=data_dir, transform=transform)\nclasses = dataset.classes\nprint(\"C√°c l·ªõp:\", classes)\nprint(\"T·ªïng s·ªë ·∫£nh:\", len(dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T15:03:39.036885Z","iopub.execute_input":"2025-10-20T15:03:39.037792Z","iopub.status.idle":"2025-10-20T15:03:44.962551Z","shell.execute_reply.started":"2025-10-20T15:03:39.037764Z","shell.execute_reply":"2025-10-20T15:03:44.961903Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_indices, val_indices, test_indices = [], [], []\ntargets = np.array([label for _, label in dataset.samples])\n\nfor c in range(len(classes)):\n    idx = np.where(targets == c)[0]\n    n_total = len(idx)\n    n_train = int(0.7 * n_total)\n    n_val = int(0.15 * n_total)\n    train_indices.extend(idx[:n_train])\n    val_indices.extend(idx[n_train:n_train + n_val])\n    test_indices.extend(idx[n_train + n_val:])\n\ntrain_ds = Subset(dataset, train_indices)\nval_ds = Subset(dataset, val_indices)\ntest_ds = Subset(dataset, test_indices)\n\nprint(f\"Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T15:12:39.235179Z","iopub.execute_input":"2025-10-20T15:12:39.235517Z","iopub.status.idle":"2025-10-20T15:12:39.244559Z","shell.execute_reply.started":"2025-10-20T15:12:39.235488Z","shell.execute_reply":"2025-10-20T15:12:39.243841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def count_classes(subset):\n    counts = [0] * len(classes)\n    for idx in subset.indices:\n        _, label = dataset.samples[idx]\n        counts[label] += 1\n    return counts\n\ntrain_counts = count_classes(train_ds)\nval_counts = count_classes(val_ds)\ntest_counts = count_classes(test_ds)\n\nx = np.arange(len(classes))\nwidth = 0.25\nplt.figure(figsize=(10,5))\nplt.bar(x - width, train_counts, width, label='Train', color='#4CAF50')\nplt.bar(x, val_counts, width, label='Val', color='#FFC107')\nplt.bar(x + width, test_counts, width, label='Test', color='#2196F3')\nplt.xticks(x, classes, rotation=45)\nplt.xlabel(\"Lo·∫°i g·∫°o\")\nplt.ylabel(\"S·ªë l∆∞·ª£ng ·∫£nh\")\nplt.title(\"Ph√¢n b·ªë d·ªØ li·ªáu Train / Validation / Test\")\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T15:12:46.354227Z","iopub.execute_input":"2025-10-20T15:12:46.354866Z","iopub.status.idle":"2025-10-20T15:12:46.616144Z","shell.execute_reply.started":"2025-10-20T15:12:46.354842Z","shell.execute_reply":"2025-10-20T15:12:46.615318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 32\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\nval_loader   = DataLoader(val_ds, batch_size=batch_size, num_workers=2, pin_memory=True)\ntest_loader  = DataLoader(test_ds, batch_size=batch_size, num_workers=2, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T15:12:53.189035Z","iopub.execute_input":"2025-10-20T15:12:53.189872Z","iopub.status.idle":"2025-10-20T15:12:53.194429Z","shell.execute_reply.started":"2025-10-20T15:12:53.189843Z","shell.execute_reply":"2025-10-20T15:12:53.193645Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = models.mobilenet_v2(pretrained=True)\nfor param in model.features.parameters():\n    param.requires_grad = False\n\nmodel.classifier[1] = nn.Linear(model.last_channel, len(classes))\nmodel = model.to(device)  # üí• Quan tr·ªçng: ƒë∆∞a model sang GPU\n\nprint(\"Model ƒëang ch·∫°y tr√™n:\", next(model.parameters()).device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T15:04:08.798738Z","iopub.execute_input":"2025-10-20T15:04:08.799456Z","iopub.status.idle":"2025-10-20T15:04:09.226173Z","shell.execute_reply.started":"2025-10-20T15:04:08.799430Z","shell.execute_reply":"2025-10-20T15:04:09.225555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = 8\ntrain_losses, val_losses, train_accs, val_accs = [], [], [], []\n\nfor epoch in range(epochs):\n    model.train()\n    running_loss, correct, total = 0, 0, 0\n\n    for imgs, labels in train_loader:\n        imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)  # üí• B·∫Øt bu·ªôc\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        _, preds = torch.max(outputs, 1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = correct / total\n\n    model.eval()\n    val_loss, val_correct, val_total = 0, 0, 0\n    with torch.no_grad():\n        for imgs, labels in val_loader:\n            imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, preds = torch.max(outputs, 1)\n            val_correct += (preds == labels).sum().item()\n            val_total += labels.size(0)\n\n    val_loss /= len(val_loader)\n    val_acc = val_correct / val_total\n    \n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    train_accs.append(train_acc)\n    val_accs.append(val_acc)\n\n    print(f\"Epoch {epoch+1}/{epochs} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T15:04:15.938785Z","iopub.execute_input":"2025-10-20T15:04:15.939068Z","iopub.status.idle":"2025-10-20T15:05:26.603659Z","shell.execute_reply.started":"2025-10-20T15:04:15.939042Z","shell.execute_reply":"2025-10-20T15:05:26.602734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nplt.subplot(2,1,1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Val Loss')\nplt.title(\"Bi·ªÉu ƒë·ªì h√†m m·∫•t m√°t\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.subplot(2,1,2)\nplt.plot(train_accs, label='Train Acc')\nplt.plot(val_accs, label='Val Acc')\nplt.title(\"Bi·ªÉu ƒë·ªì ƒë·ªô ch√≠nh x√°c\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T15:11:47.640633Z","iopub.execute_input":"2025-10-20T15:11:47.641330Z","iopub.status.idle":"2025-10-20T15:11:48.066044Z","shell.execute_reply.started":"2025-10-20T15:11:47.641300Z","shell.execute_reply":"2025-10-20T15:11:48.065273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\ny_true, y_pred = [], []\nwith torch.no_grad():\n    for imgs, labels in test_loader:\n        imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        outputs = model(imgs)\n        _, preds = torch.max(outputs, 1)\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n\ncm = confusion_matrix(y_true, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\ndisp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\nplt.title(\"Confusion Matrix - MobileNetV2 Rice Classification\")\nplt.show()\n\nprint(\"           \\n---B√°o c√°o ph√¢n lo·∫°i---\\n\")\nprint(classification_report(y_true, y_pred, target_names=classes))\n\ntorch.save(model.state_dict(), \"mobilenetv2_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T15:11:52.171480Z","iopub.execute_input":"2025-10-20T15:11:52.172261Z","iopub.status.idle":"2025-10-20T15:11:55.126517Z","shell.execute_reply.started":"2025-10-20T15:11:52.172235Z","shell.execute_reply":"2025-10-20T15:11:55.125643Z"}},"outputs":[],"execution_count":null}]}